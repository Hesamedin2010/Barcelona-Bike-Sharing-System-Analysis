{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "126a89a3-1326-46f0-9b21-daae3751c7df",
   "metadata": {},
   "source": [
    "# Analyze bike-sharing system of Barcelona - Spark DataFrame-based programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3264b1d8-f22f-44bb-b1cc-03ab267f0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this analysis, I am going to consider the occupancy of the stations where users can pick up or drop off\n",
    "# bikes in order to identify the most \"critical\" timeslots (day of the week, hour) for each station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef22e070-7ce9-490c-a992-e8bd695ac0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is located on the big data cluster and I am going to read data from there.\n",
    "# there are two types of data:\n",
    "# 1. register.csv: This contains the historical information about the number of used and free slots for\n",
    "#    ~3000 stations from May 2008 to September 2008. Each line of register.csv\n",
    "#    corresponds to one reading about the situation of one station at a specific timestamp.\n",
    "# 2. stations.csv: It contains the description of the stations (station_id, latitude, longitude, name). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49cc2ec-c0ff-4900-80a3-90330c678e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "registerPath = \"/data/students/bigdata_internet/lab3/register.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d060f87a-f778-464a-a39f-102a7f7845ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationPath = \"/data/students/bigdata_internet/lab3/stations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2eaea-d680-459b-9d89-ae7ab85c83dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''In this analysis, PySpark was utilized for its robust distributed computing capabilities, \n",
    "ideal for handling large datasets efficiently.\n",
    "If you're using the PySpark shell, no additional setup is necessary. \n",
    "However, for those working in a Python environment, setting up PySpark involves the following steps:\n",
    "1. Install PySpark: Begin by installing PySpark using pip:\n",
    "pip install pyspark\n",
    "2. Configure PySpark: In your Python script or interactive session, include the following configuration \n",
    "to initialize PySpark:\n",
    "```python\n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setAppName(\"MyApp\")\n",
    "sc = SparkContext(conf=conf)\n",
    "```\n",
    "Ensure to execute this configuration before performing any PySpark operations.\n",
    "For comprehensive installation and configuration instructions, refer to the official PySpark documentation: \n",
    "PySpark Installation Guide\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010354c4-5bcc-4821-90c3-ffe7878c8ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading register data as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f34e8c2-f6c6-4503-8e0d-6752f8769ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb7e2a-47d2-4cb2-adcb-d66cfa1800e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file is separated with tab so I will pu the separator \\t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "064b9e9c-6ab3-451b-9ab0-15686bbf38d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "registerDF = spark.read.load(registerPath, format=\"csv\", header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9122dd07-5284-4e54-a08e-5c8612aa2c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25319028"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registerDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281d1f0-5943-4314-ae4d-5d58d9157aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clean the data, I am going to filter data that their used_slot != 0 or their free_slot != 0 \n",
    "# because whether there are some bicycles in station or not and it is not possible to have 0 for both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e86b505-b012-4921-8725-53cd56a2d16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "registerDF_clean = registerDF.filter(\"used_slots != 0 OR free_slots != 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "870c8d50-53c8-46a2-9ebc-7f4f9f781c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25104121"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registerDF_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55ca6a-cbb0-487f-8d47-506937e87e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 25,319,028 rows (without the header) in the original file and it decreases to 25,104,121 \n",
    "# (without the header) after we did the filter and deleted wrong data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52108b1b-f732-433d-8cab-19df681895c4",
   "metadata": {},
   "source": [
    "1.2 stations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d7e688-ab3f-4509-bbfb-dafad25b4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading station data as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b60cfd08-347c-4758-82ee-e6a3b52de5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationDF = spark.read.load(stationPath, format=\"csv\", header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5371e-bf12-431d-a4f6-08c1de0abc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a Spark application that selects the pairs (station, timeslot) that are characterized \n",
    "# by a high \"criticality\" value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e125b1e-7c61-4cbf-99f5-561666fe2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to timeslot (weekday, hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd13eac8-9c92-4792-aaae-fc2d47e18acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "registerDF_timeslot = registerDF_clean.selectExpr(\"station\", \"(date_format(timestamp,'EEEE'), hour(timestamp)) as timeslot\", \"used_slots\", \"free_slots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dd4901-405c-4471-9e8f-45f9bce965de",
   "metadata": {},
   "source": [
    "........................................................................................"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9d5bc5-079a-46c3-9188-00c16e9a1288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the criticality value C(Si, Tj) for each pair (Si, Tj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b19bad-1727-472a-be0f-1180c00902bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only those data that have free_slot = 0 which means that all of the slots were used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ecd7b61-12a7-48a3-8edc-b98d09ae3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroFreeSlots = registerDF_timeslot.filter(\"free_slots = 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c5ab71-2a4b-4d46-8f65-ce51a008872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe based on (station_id, timeslot) and count the number of free_slots = 0 readings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6380f25c-4d18-4fa6-8cda-64aefd60bafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroFreeSlotsGroup = zeroFreeSlots.groupBy(\"station\", \"timeslot\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff9cd40-822d-4143-86ce-439f7fe03aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e2bddd8-516b-4d17-a414-4b5be8d39dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroFreeSlotsGroup = zeroFreeSlotsGroup.withColumnRenamed(\"count\", \"count_zero_free_slots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a2865-9670-4c5b-b3bd-b028edd5633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the original dataframe based on (station_id, timeslot) and count the number of all readings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3959dba8-0bad-43bd-b677-6a1c21db0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "registerDFTotalGroup = registerDF_timeslot.groupBy(\"station\", \"timeslot\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b886f0-0273-446a-98aa-227dc57c29c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc8bc028-08d7-4ebc-866a-0af05ef407c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "registerDFTotalGroup = registerDFTotalGroup.withColumnRenamed(\"count\", \"count_total_free_slots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c91272b-c901-4187-8d08-6969e24cbe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join two previous dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95308b1a-2394-4cb1-b34f-3a91eb5a4519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/23 09:02:30 WARN sql.Column: Constructing trivially true equals predicate, 'station#10 = station#10'. Perhaps you need to use aliases.\n",
      "23/12/23 09:02:30 WARN sql.Column: Constructing trivially true equals predicate, 'timeslot#36 = timeslot#36'. Perhaps you need to use aliases.\n"
     ]
    }
   ],
   "source": [
    "joinedRegister = zeroFreeSlotsGroup.join(\n",
    "    registerDFTotalGroup,\n",
    "    (zeroFreeSlotsGroup.station == registerDFTotalGroup.station) &\n",
    "    (zeroFreeSlotsGroup.timeslot == registerDFTotalGroup.timeslot)\n",
    ").select(\n",
    "    zeroFreeSlotsGroup['station'],\n",
    "    zeroFreeSlotsGroup['timeslot'],\n",
    "    zeroFreeSlotsGroup['count_zero_free_slots'],\n",
    "    registerDFTotalGroup['count_total_free_slots']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b8a84b-f1c8-4000-bfbc-3acba919fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the criticality value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c085e1c-d097-4cb8-a832-8c0fe96c01ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "criticalityRegister = joinedRegister.selectExpr(\"station\", \"timeslot\", \"count_zero_free_slots/count_total_free_slots as criticality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92124432-e62a-4acb-907e-93d3839761cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, I will select only the critical pairs (Si, Tj) having a criticality value C(Si, Tj) greater than \n",
    "# a minimum threshold (0.6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00e8e05c-5f3a-4aee-bf02-82eb6d3d49fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criticalRegister = criticalityRegister.filter(\"criticality >= 0.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35dd006-c7c4-4373-bbc4-61be913cc340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the results by increasing criticality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a05be7ec-7c3a-4f85-b92f-34395830f713",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderedCriticalRegister = criticalRegister.sort(\"criticality\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b6606-4528-43f6-9df6-218ad83f254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the most critical (station_id, timeslot) in Barcelona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada9f913-7cc6-466b-a90e-8e439c428c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderedCriticalRegister.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa3f809-f10f-4add-8b53-c41c1369c8d7",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5edce6d-90e1-4d79-872b-0b4226a3ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the sorted critical pairs C(Si, Tj) in the output folder (also an argument of the application), \n",
    "# by using a csv files (with header), where columns are separated by \"tab\". Store exactly the following \n",
    "# attributes separated by a \"tab\":\n",
    "# station / station longitude / station latitude / day of week / hour / criticality value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5667a29a-741d-48fb-8749-8288452e5c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join critical stations dataframe from register data with station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87f4e643-f306-4cc5-90c8-751054abba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "criticalOutput = orderedCriticalRegister.join(\n",
    "    stationDF, orderedCriticalRegister.station == stationDF.id).select(\n",
    "    orderedCriticalRegister[\"station\"], \n",
    "    stationDF[\"longitude\"], \n",
    "    stationDF[\"latitude\"], \n",
    "    orderedCriticalRegister[\"timeslot\"], \n",
    "    orderedCriticalRegister[\"criticality\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ced223b2-7ad4-4c48-b83c-45760e187d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "orderedCriticalOutput = criticalOutput.sort(\"criticality\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a5172-3056-44a0-914e-4068fa2eed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the function for week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f38736fe-7f8b-404c-8aa9-de0266f72dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register('week', lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d243d735-69ce-489b-a563-3b1e8a21d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the function for hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36f1b410-0a5b-479f-86fe-53a7e4a70284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/23 09:02:46 WARN analysis.SimpleFunctionRegistry: The function hour replaced a previously registered function.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(y)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register('hour', lambda y: y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4cab6b-cef8-4dd2-93cf-1e3520aa8535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b57b4fb-ef4f-4196-bf7a-23a4a1684158",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDF = orderedCriticalOutput.selectExpr(\"station\", \"longitude\", \"latitude\", \"week(timeslot) as week\", \"hour(timeslot) as hour\", \"criticality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a6d49-87cf-4ce8-bddf-8a61c3669da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "563b93e5-18c4-4792-b634-acd62806df9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "finalDF.write.csv('critical-stations-Barcelona-DataFrame', header=True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f428966-6919-42a4-8d8f-5641112b3d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:=============================>                            (2 + 2) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+--------+----+------------------+\n",
      "|station|longitude| latitude|    week|hour|       criticality|\n",
      "+-------+---------+---------+--------+----+------------------+\n",
      "|      9| 2.185294|41.385006|  Friday|  10|0.6129032258064516|\n",
      "|     10| 2.185206|41.384875|Saturday|   0| 0.622107969151671|\n",
      "|     58| 2.170736|41.377536|  Monday|   1|0.6239554317548747|\n",
      "|      9| 2.185294|41.385006|  Friday|  22|0.6258389261744967|\n",
      "|     58| 2.170736|41.377536|  Monday|   0|0.6323119777158774|\n",
      "+-------+---------+---------+--------+----+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "finalDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa57ccd2-1974-4108-9d10-94049797709e",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c43d9-5cb6-4bd2-907c-611f6c387d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section, I am going to compute the distance between each station and the city center. \n",
    "# The city center has coordinates:\n",
    "# latitude = 41.386904\n",
    "# longitude = 2.169989\n",
    "# To compute the distance implement the Haversine function (use the formula \n",
    "# in https://en.wikipedia.org/wiki/Haversine_formula).\n",
    "# Then, compute the average number of used_slots per station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2be7a6-f4af-4eff-8300-8f8e25b37cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the latitude and longitude columns to double type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5faff9a4-c916-48db-8ccd-cec6315519d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acc7c802-57dc-4782-8a8b-2cebcdb5ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationDF = stationDF.withColumn(\"latitude\", stationDF[\"latitude\"].cast(\"double\"))\n",
    "stationDF = stationDF.withColumn(\"longitude\", stationDF[\"longitude\"].cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375fcc75-6c1a-4ee8-a8aa-bf032273894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to compute the haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4479a202-336e-4807-ab1e-dc66a48401bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def haversine(lat, lon):\n",
    "    # City center coordination\n",
    "    lat1 = 41.386904\n",
    "    lon1 = 2.169989\n",
    "    # Radius of the Earth in kilometers\n",
    "    R = 6371.0\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat, lon = map(math.radians, [lat1, lon1, lat, lon])\n",
    "    dlat = lat - lat1\n",
    "    dlon = lon - lon1\n",
    "    hav = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat) * math.sin(dlon / 2) ** 2\n",
    "    distance = 2 * R * math.asin(math.sqrt(hav))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7080bfb-d3f6-4fbd-af42-f0cca59c11f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the haversine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "468a68e6-8505-409f-9116-d4eb2a9b06d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.haversine(lat, lon)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register('hav', haversine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dddefc-0aed-4c55-944c-1959ef21d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b18b0c5-31ab-4620-a049-07ac629f58e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dinstanceStationDF = stationDF.selectExpr(\"id\", \"hav(latitude, longitude) as distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb5903-7f40-45cf-8538-cbbb5f3ee6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the distanceStationDF dataframe with cleaned register dataframe and select the desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77bf731f-4033-4c4d-921b-5a96c0c306dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedRegisterStation = registerDF_clean.join(\n",
    "    dinstanceStationDF, registerDF_clean.station == dinstanceStationDF.id).select(\n",
    "        registerDF_clean['station'], \n",
    "        registerDF_clean['used_slots'], \n",
    "        dinstanceStationDF['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ee014-6122-4654-90db-c93046fd722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, I want to find the stations that are closer than 1.5 km from the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe7934-f1a0-4685-9e73-4ae3300d07d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter distance closer than 1.5 km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9d37c30-f2f5-4b6d-b4df-674872974d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "closerStations = joinedRegisterStation.filter(\"distance < 1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a2328-31de-4836-84e8-a2472f19c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the used_slots column to float type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e866bc9e-a4c5-42c8-a0e3-255a426dd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "closerStations = closerStations.withColumn(\"used_slots\", closerStations[\"used_slots\"].cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd9948-b07c-4f91-98d4-907a7fbcafbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average of used_slots for closer stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dda6bbee-c046-4b0f-a667-bdc7ed54f3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgCloserStations = closerStations.agg({\"used_slots\": \"avg\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f49e6ac-3ac3-4e85-8dba-c6fa6df4e6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=================================================>        (6 + 1) / 7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|avg(used_slots)|\n",
      "+---------------+\n",
      "| 8.174875311666|\n",
      "+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "avgCloserStations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82df11-d4b6-4d56-88f8-70f5ca009362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, I am going to find the stations that are farther than 1.5 km from the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69601e76-9d05-4fde-8705-1ad5e1ba109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter distance further than 1.5 km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7438245-ba4a-48d2-b204-b5e7582a209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "furtherStations = joinedRegisterStation.filter(\"distance >= 1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f6f3cb-880f-46ec-9fba-6e824dfefd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average of used_slots for further stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec41d487-d485-4101-b5eb-95fccafdf734",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgFurtherStations = furtherStations.agg({\"used_slots\": \"avg\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1283482-15aa-4f2f-bece-2717961d1e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=================================================>        (6 + 1) / 7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|  avg(used_slots)|\n",
      "+-----------------+\n",
      "|7.913817257872483|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "avgFurtherStations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106a9f65-21dc-4112-a414-96f082356eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result shows that the average of used slots of closer ones is higher than further ones. \n",
    "# The average of used slots for closer stations is 8.17 and it is 7.91 for further ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
